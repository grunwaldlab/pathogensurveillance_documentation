---
title: "Tutorial"
editor: visual
format:
  html:
    df-print: kable
params: 
  inputs: "tutorial_data/all_inputs"
---

```{r load_libraries, warning=FALSE, message=FALSE}
#| echo: false
library(dplyr)
library(ggplot2)
library(readr)
library(knitr)
library(purrr)
library(yaml)
library(phylocanvas)
library(ape)
library(magrittr)
library(pheatmap)
library(heatmaply)
library(tidyverse)
library(palmerpenguins)
library(ade4)
library(adegenet)
library(poppr)
library(ggtree)
library(igraph)
library(visNetwork)
library(phangorn)
library(ggplot2)
library(ggnewscale)
library(kableExtra)
library(plotly)
library(webshot2)
library(metacoder)
library(ggdendro)
library(rcrossref)
library(psminer)
```

```{r parse_inputs}
#| echo: false
#| output: false
group_path <- file.path(params$inputs, "group_id.txt")
sample_data_path <- file.path(params$inputs, "samp_data.csv")
ref_data_path <- file.path(params$inputs, "ref_data")
assigned_refs_path <- file.path(params$inputs, "assigned_refs.csv")

group <- read_lines(group_path)
sample_data <- psminer::parse_sample_meta(sample_data_path, assigned_refs_path, group)
ref_data <- psminer::parse_ref_meta(ref_data_path, assigned_refs_path, sample_data_path, group)

# Parse sendsketch data
sendsketch_paths <- list.files(file.path(params$inputs, "sendsketch"), full.names = T)
sketch_data <- psminer::parse_sendsketch(sendsketch_paths)

# Parse variant data
variant_data_path <- file.path(params$inputs, "variant_data")
snp_tree_paths <- list.files(variant_data_path, pattern = "\\.treefile$", full.names = TRUE)
vcf_paths <- list.files(variant_data_path, pattern = "\\.vcf\\.gz$", full.names = TRUE)
snp_align_paths <- list.files(variant_data_path, pattern = "\\.fasta$", full.names = TRUE)

# Parse ANI matrix
ani_matrix_path <- file.path(params$inputs, "ani_matrix.csv")
ani_matrix <- psminer::parse_ani_matrix(ani_matrix_path)

# Parse POCP matrix
pocp_matrix_path <- file.path(params$inputs, "pocp.tsv")
pocp_matrix <- psminer::parse_pocp_matrix(pocp_matrix_path)

# Parse core gene phylogeny
core_phylo_dir_path <- file.path(params$inputs, "core_phylo")
core_phylo_paths <- list.files(core_phylo_dir_path, pattern = "\\.treefile$", full.names = TRUE)

# Parse quality control data (currently not used)
multiqc_path <- file.path(params$inputs, "multiqc")
multiqc_report_path <- file.path(multiqc_path, 'multiqc_report.html')
quast_path <- file.path(params$inputs, "quast")
quast_ref_names <- list.files(quast_path)
quast_report_paths <- file.path(quast_path, quast_ref_names, 'report.html')

# Parse messages
messages_path <- file.path(params$inputs, "messages.tsv")
messages <- readr::read_tsv(messages_path)

# Parse version data
version_path <- file.path(params$inputs, "versions.yml")
version_data <- psminer::parse_software_meta(version_path)

```

```{r parse_snp_align}
#| echo: false
#| output: false
snp_alignments <- parse_alignment_fastas(snp_align_paths, group)
n_variants <- unlist(lapply(snp_alignments, ncol))
snp_ref_names <- unlist(lapply(names(snp_alignments), function(id) ref_data$reference_name[! is.na(ref_data$reference_name) & ref_data$reference_id == id]))
names(snp_ref_names) <- names(snp_alignments)
```

```{r parse_snp_trees}
#| echo: false
#| output: false
snp_trees <- parse_snp_trees(snp_tree_paths, group)
n_samples <- unlist(lapply(snp_trees, function(tree) length(tree$tip.label) - 1))

```

This example uses sequencing reads from an outbreak of *Xanthomonas hortorum* in several plant nurseries. For the sake of this example, we'll treat the pathogen as an unknown and use the pathogensurveillance pipeline to help determine its identity. We'll also explore how isolates from different nursery populations relate to each other and the reference sequences of other closely-related organisms. This information can be obtained from several plots that the pathogensurveillance pipeline generates automatically.
<br/><br/>

### Sample input

The pipeline is designed to work with a wide variety of existing metadata sheets without extensive changes. Here's a look at "xanthomonas.csv", which serves as the only unique input file within the command to run the pipeline:

```{r}
#| echo: false
#| message: false
#| comment: ""
library(tidyverse)
df = read.csv("data/xanthomonas.csv")
df |> head()
```

There is quite a bit of information in this file, but only a few columns are essential (and can be in any order). The input csv needs show the pipeline where to find the sequencing reads. These can be present either locally or they can be downloaded.

**Using local reads**: Columns "shortread_1" and "shortread_2" specify the path to forward and reverse reads. Each row corresponds to one individual sample. Reads for this tutorial are hosted on the pathogensurveilance github repo. They are derived from paired-end illumina shortreads, but the pipeline will also work with mixed inputs of Pacbio or Oxford Nanopore sequences.

**Downloading reads**: Sequence files may instead be hosted on the ncbi. In that case, the "shortread_1/shortread_2" columns should be substituted with a single "SRA" column, and they will be downloaded from the ncbi automatically. See test/data/metadata/xanthomonas.csv for an example using this input format.

**Specifying a reference genome (optional)**: The "reference_refseq" column may be useful when you are relatively confident as to the identity of your samples and would like to include one particular reference for comparison. See Documentation for an in-depth explanation of how to designate mandatory and optional references.

**Assigning sample groups (optional)**: The optional column "color_by" is used for data visualization. It will assign one or more columns to serve as grouping factors for the output report. Here, samples will be grouped by the values of the "year" and "nursery" columns. Note that multiple factors need to be separated by semicolons within the color_by column.
<br/><br/>

### Running the pipeline

Here is the full command used execute this example, using a docker container:

``` bash
nextflow run nf-core/pathogensurveillance --input https://raw.githubusercontent.com/grunwaldlab/pathogensurveillance/master/test/data/metadata/xanthomonas.csv --outdir xanthomonas --download_bakta_db true -profile docker -resume --max_cpus 8 --max_memory 30GB -resume
```

When running your own analysis, you will need to provide your own path to the input CSV file.

By default, the pipeline will run on 128 GB of RAM and 16 threads. This is more resources than is strictly necessary and beyond the capacity of most desktop computers. We can scale this back a bit for this lightweight test run. This analysis will work with 8 cpus and 30 GB of RAM (albeit more slowly), which is specified by the --max_cpus and --max_memory settings.

The setting `-resume` is only necessary when resuming a previous analysis. However, it doesn't hurt to include it at the start. If the pipeline is interrupted, this setting allows progress to pick up where it left off â€“ as long as the previous command is executed from the same working directory.

If the pipeline begins successfully, you should see a screen tracking your progress:

``` bash
[25/63dcee] process > PATHOGENSURVEILLANCE:INPUT_CHECK:SAMPLESHEET_CHECK (xanthomonas.csv)[100%] 1 of 1

[-        ] process > PATHOGENSURVEILLANCE:SRATOOLS_FASTERQDUMP                              -

[-        ] process > PATHOGENSURVEILLANCE:DOWNLOAD_ASSEMBLIES                               -

[-        ] process > PATHOGENSURVEILLANCE:SEQKIT_SLIDING                                    -

[-        ] process > PATHOGENSURVEILLANCE:FASTQC                                            -

[-        ] process > PATHOGENSURVEILLANCE:COARSE_SAMPLE_TAXONOMY:BBMAP_SENDSKETCH           -
```

The input and output of each process can be accessed from the work/ directory. The subdirectory within work/ is designated by the string to left of each step. Note that this location will be different each time the pipeline is run, and only the first part of the name of the subdirectory is shown. For this run, we could navigate to `work/25/63dcee(etc)` to access the input csv that is used for the next step.
<br/><br/>

### Report

You should see a message similar to this if the pipeline finishes successfully:

``` bash
-[nf-core/plantpathsurveil] Pipeline completed successfully-

To clean the cache, enter the command: 
nextflow clean evil_boyd -f 

Completed at: 20-May-2024 12:44:40
Duration    : 3h 29m 2s
CPU hours   : 15.2
Succeeded   : 253
```

The final report can be viewed as either a .pdf or .html file. It can be accessed inside the reports folder of the output directory (here: `xanthomonas/reports`). This report shows several key pieces of information about your samples.

A note on storage management - pathogensurveillance creates a large number of intermediate files. For most users we recommend clearing these files after each run. To do so, run the script shown after the completion message (nextflow clean <your_run_name> -f). You would not want to do this if: (1) You still need to use the caching system. For example, imagine you would like to compare a new sample to 10 samples from a previous run. In that case some files could be reused to make the pipeline work more quickly. (2) You would like to use intermediate files for your own analysis. By default, these files are saved in the output directory as symlinks to their location in the work/ directory, so you would need to retrieve these before clearing the cache. You could use alternatively use the option --copymode high to save all intermediate files to the published directory, though in the short term this doubles the storage footprint of each run.

This particular report has been included as an example under `test/sample_reports/xanthomonas`.

**Summary:**

-   **Pipeline Status Report**: error messages for samples or sample groups
-   **Input Data**: Data read from the input .csv file

---

**Identification:**

-   **Initial identification**: Coarse identification from the bbmap sendsketch step. The first tab shows best species ID for each sample*.* The second tab shows similarity metrics between sample sequences and other reference genomes: %ANI (average nucleotide identity), %WKID (weighted kmer identity), and %completeness.

    -   For more information about each metric, click the **About this table** tab underneath.

```{r}
#| echo: false
psminer::print_pocp_table(pocp_matrix, sample_data, ref_data)
```
---

```{r ani_heatmap, fig.height = 5}
#| echo: false
psminer::make_ani_heatmap(ani_matrix * 100, ref_data, sample_data)
```
---



**Most similar organisms**: Shows relationships between samples and references using % ani and % pocp (percentage of conserved proteins). For better resolution, you can interactively zoom in/out of plots.

    **Phylogenetic context** ![](images/report_core_gene_phylogeny.png)

**Core gene phylogeny**: A core gene phylogeny uses the sequences of all gene shared by all of the genomes included in the tree to infer evolutionary relationships. It is the most robust identification provided by this pipeline, but its precision is still limited by the availability of similar reference sequences. Methods to generate this tree differ between prokaryotes and eukaryotes. Our input to the pipeline was prokaryotic DNA sequences, and the method to build this tree is based upon many different core genes shared between samples and references (for eukaryotes, this is constrained to BUSCO genes). This tree is built with iqtree and based upon shared core genes analyzed using the program pirate. You can highlight branches by hovering over and clicking on nodes.

---

**SNP trees**

```{r plot_snp_trees, results='asis', eval = length(snp_trees) > 0, fig.height = 5, fig.width=5}
#| echo: false
for (id in names(snp_trees)) {
    #cat(paste0('::: panel-tabset\n### ', id, '\n\n'))
    #cat(paste0('#### **', n_samples[id], ' samples with ', n_variants[id], ' variants aligned to reference "', snp_ref_names[id], '":** \n\n'))
    snp_tree_plot <- psminer::make_phylogeny(snp_trees[[id]], sample_data, ref_data)
    #if (knitr::is_html_output()) {cat(as.character(htmltools::as.tags(a_plot, standalone = TRUE)))} #else {
#        print(a_plot)
#    }
    #cat('\n:::')
}
snp_tree_plot
```

-   This tree is better suited for visualizing the genetic diversity among samples. However, the core gene phylogeny provides a much better source of information for evolutionary differences among samples and other known references.

---

**Minimum spanning network**

![](images/Xan_MSN_0.01.png)

**Minimum spanning network**: The nodes represent unique multilocus genotypes, and the size of nodes is proportional to the \# number of samples that share the same genotype. The edges represent the SNP differences between two given genotypes, and the darker the color of the edges, the fewer SNP differences between the two.

---

