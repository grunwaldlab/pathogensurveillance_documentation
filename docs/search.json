[
  {
    "objectID": "documentation.html",
    "href": "documentation.html",
    "title": "Documentation",
    "section": "",
    "text": "Required:\n\n--input: Path to comma-separated file containing information about the samples in the experiment.\n--output: The output directory where the results will be saved. You have to use absolute paths to storage on Cloud infrastructure.\n--bakta_db: The path to the Bakta database folder. This or --download_bakta_db must be included.\n--download_bakta_db: Download the database required for running Bakta. Note that this will download gigabytes of information, so if you plan on running the pipeline repeatedly it would be better to download the database manually and specify the path with --bakta_db.\n\nNextflow Options:\n\n-profile: Instructs the pipeline to use the named tool for software management. docker, singularity, podman, shifter, charliecloud and conda. For example, -profile test,docker\n-resume: Restarts an incomplete run by using cached intermediate files.\n\nOptional:\n\n--email: Set this parameter to your e-mail address to get a summary e-mail with details of the run sent to you when the workflow exits. If set in your user config file (`~/.nextflow/config`) then you don’t need to specify this on the command line for every run.\n--multiqc_title: MultiQC report title. Printed as page header, used for filename if not otherwise specified.\n\nPerformance Parameters:\n\n--max_cpus: Maximum number of CPUs that can be requested for any single job. Default: 16\n--max_memory: Maximum amount of memory that can be requested for any single job. Default: 128.GB\n--max_time: Maximum amount of time that can be requested for any single job. Default: 240.h\n\nAnalysis Parameters:\n\n--sketch_max_depth: Depth reads are subsampled to for the initial sketch-based identification. Default: 3\n--variant_max_depth: Depth reads are subsampled to for the variant-based parts of the analysis. Default: 15\n--assembly_max_depth: Depth reads are subsampled to for genome assembly. This will be multiplied by the predicted ploidy of each sample. Default: 30\n--refseq_download_num: The maximum number of RefSeq sequences to select and download for each sample at each taxonomic level (species, genus, and family). The total number will vary based on the diversity of samples. Default: 10\n--min_core_genes: The minimum number of genes needed to conduct a core gene phylogeny. Samples and references will be removed (as allowed by the min_core_samps and min_core_refs options) until this minimum is met. Default: 10\n--min_core_samps: The minimum proportion of samples needed to conduct a core gene phylogeny. Samples will be removed until the min_core_genes option is satisfied or this minimum is met. Default: 0.8\n--min_core_refs: The minimum proportion of references needed to conduct a core gene phylogeny. References will be removed until the min_core_genes option is satisfied or this minimum is met. Default: 0.5\n--max_core_genes: The maximum number of genes used to conduct a core gene phylogeny. Default: 100\n--min_ref_ani: The minimum ANI between a sample and potential reference for that reference to be used for variant calling with that sample. To force all the samples in a report group to use the same reference, set this value very low. Default: 0.9\n--copymode: Storage management setting to determine which files will be copied from the cache into the output directory.\n\nhigh - All files are copied into output directory.\nmedium - Reports are copied. Large sequencing files are not copied, but they are accessible through symlinks to their location in the cache (default).\nlow - No files are copied into output directory, but files are accessible through symlinks to their location in the cache.",
    "crumbs": [
      "Documentation"
    ]
  },
  {
    "objectID": "documentation.html#benchmarks",
    "href": "documentation.html#benchmarks",
    "title": "Documentation",
    "section": "Benchmarks",
    "text": "Benchmarks\nxanthomonas.csv\n(with all reads + Bakta database already downloaded):\n\n29 samples\nRun duration: 2h 16m 7s\nStorage:\n\nlocal reads folder: 11 GB\ncache: 75 GB\noutput directory: 19 MB\n\nhardware specs:\n\nOS: Pop!_OS 22.04LTS\nProcessor: 5.7 GHz Ryzen 9 7950X (16 cores - 32 threads)\nRAM: 128 GB DDR5 3600MHz (4x32)",
    "crumbs": [
      "Documentation"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "",
    "section": "",
    "text": "NOTE: THIS PROJECT IS UNDER DEVELOPMENT AND MAY NOT FUNCTION AS EXPECTED UNTIL THIS MESSAGE GOES AWAY",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "",
    "section": "Introduction",
    "text": "Introduction\nnf-core/pathogensurveillance is a population genomic pipeline for pathogen diagnosis, variant detection, and biosurveillance. The pipeline accepts the paths to raw reads for one or more organisms (in the form of a CSV file) and creates reports in the form of interactive HTML reports or PDF documents. Significant features include the ability to analyze unidentified eukaryotic and prokaryotic samples, creation of reports for multiple user-defined groupings of samples, automated discovery and downloading of reference assemblies from NCBI RefSeq, and rapid initial identification based on k-mer sketches followed by a more robust core genome phylogeny and SNP-based phylogeny.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#pipelinesummary",
    "href": "index.html#pipelinesummary",
    "title": "",
    "section": "Pipeline summary",
    "text": "Pipeline summary\nThis is a quick breakdown of the processes used by PathogenSurveillance:\n\nDownload sequences and references if they are not provided locally\nGenome assembly\n\nIllumina shortreads: (spades)\nPacbio or Oxford Nanopore longreads: (flye)\n\nQuickly obtain several initial sample references (bbmap)\nMore accurately select appropriate reference genomes. Genome “sketches” are compared between first-pass references, samples, and any references directly provided by the user (sourmash)\nGenome annotation (bakta)\nAlign reads to reference sequences (bwa)\nVariant calling and filtering (graphtyper, vcflib)\nDetermine relationship between samples and references\n\nBuild SNP tree from variant calls (iqtree)\nFor Prokaryotes:\n\nIdentify shared orthologs (pirate)\nBuild tree from core genome phylogeny (iqtree)\n\nFor Eukaryotes:\n\nIdentify BUSCO genes (busco)\nBuild tree from BUSCO genes (read2tree)\n\n\nGenerate interactive html report/pdf file\n\nSequence and assembly information (fastqc, multiqc, quast)\nsample identification tables and heatmaps\nPhylogenetic trees from genome-wide SNPs and core genes\nminimum spanning network",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#flowchart",
    "href": "index.html#flowchart",
    "title": "",
    "section": "PathogenSurveillance pipeline chart",
    "text": "PathogenSurveillance pipeline chart",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "quickstart.html",
    "href": "quickstart.html",
    "title": "Quickstart",
    "section": "",
    "text": "Install Nextflow (&gt;=21.10.3)\nInstall any of Docker, Singularity (you can follow this tutorial), Podman, Shifter or Charliecloud for full pipeline reproducibility (you can use Conda both to install Nextflow itself and also to manage software within pipelines. Please only use it within pipelines as a last resort; see docs).\nDownload the pipeline and test it on a minimal dataset with a single command:\nnextflow run nf-core/pathogensurveillance -profile test,YOURPROFILE --outdir &lt;OUTDIR&gt; --download_bakta_db true -resume \nNote that some form of configuration will be needed so that Nextflow knows how to fetch the required software. This is usually done in the form of a config profile (YOURPROFILE in the example command above). You can chain multiple config profiles in a comma-separated string.\n\n\nThe pipeline comes with config profiles called docker, singularity, podman, shifter, charliecloud and conda which instruct the pipeline to use the named tool for software management. For example, -profile test,docker.\nPlease check nf-core/configs to see if a custom config file to run nf-core pipelines already exists for your Institute. If so, you can simply use -profile &lt;institute&gt; in your command. This will enable either docker or singularity and set the appropriate execution settings for your local compute environment.\nIf you are using singularity, please use the nf-core download command to download images first, before running the pipeline. Setting the NXF_SINGULARITY_CACHEDIR or singularity.cacheDir Nextflow options enables you to store and re-use the images from a central location for future pipeline runs.\nIf you are using conda, it is highly recommended to use the NXF_CONDA_CACHEDIR or conda.cacheDir settings to store the environments in a central location for future pipeline runs.\n\n\nStart running your own analysis:\n\nnextflow run nf-core/pathogensurveillance --input samplesheet.csv --outdir &lt;OUTDIR&gt; --download_bakta_db true -profile &lt;docker/singularity/podman/shifter/charliecloud/conda/institute&gt; -resume\n\nYou can also try running a small example dataset hosted with the source code using the following command (no need to download anything):\nnextflow run nf-core/pathogensurveillance --input https://raw.githubusercontent.com/grunwaldlab/pathogensurveillance/master/test/data/metadata_small.csv --outdir test_out --download_bakta_db true -profile docker -resume",
    "crumbs": [
      "Quickstart"
    ]
  },
  {
    "objectID": "tutorial.html",
    "href": "tutorial.html",
    "title": "Tutorial",
    "section": "",
    "text": "Before starting, first take a look at the Quickstart for instructions on how to download pathogensurveillance and install both Docker and Nextflow.",
    "crumbs": [
      "Tutorial"
    ]
  },
  {
    "objectID": "citations.html",
    "href": "citations.html",
    "title": "Citations",
    "section": "",
    "text": "nf-core/pathogensurveillance was written by:\nZachary S. L. Foster1, Martha Sudermann2, Camilo Parada-Rojas2, Fernanda Iruegas-Bocardo2, Ricardo Alcalá-Briseño2, Logan K. Blair 1, Alexandra J Weisberg2, Jeff H. Chang2, and Niklaus J. Grünwald1\n1Horticultural Crops Research Laboratory, USDA Agricultural Research Service, Corvallis, Oregon 97331, USA\n2Department of Botany and Plant Pathology, Oregon State University, Corvallis, Oregon 97331, USA",
    "crumbs": [
      "Citations"
    ]
  },
  {
    "objectID": "citations.html#credits",
    "href": "citations.html#credits",
    "title": "Citations",
    "section": "",
    "text": "nf-core/pathogensurveillance was written by:\nZachary S. L. Foster1, Martha Sudermann2, Camilo Parada-Rojas2, Fernanda Iruegas-Bocardo2, Ricardo Alcalá-Briseño2, Logan K. Blair 1, Alexandra J Weisberg2, Jeff H. Chang2, and Niklaus J. Grünwald1\n1Horticultural Crops Research Laboratory, USDA Agricultural Research Service, Corvallis, Oregon 97331, USA\n2Department of Botany and Plant Pathology, Oregon State University, Corvallis, Oregon 97331, USA",
    "crumbs": [
      "Citations"
    ]
  },
  {
    "objectID": "citations.html#contributionsandsupport",
    "href": "citations.html#contributionsandsupport",
    "title": "Citations",
    "section": "Contributions and Support",
    "text": "Contributions and Support\nIf you would like to contribute to this pipeline, please see the contributing guidelines.\nFor further information or help, don’t hesitate to get in touch on the Slack #pathogensurveillance channel (you can join with this invite).",
    "crumbs": [
      "Citations"
    ]
  },
  {
    "objectID": "citations.html#citations",
    "href": "citations.html#citations",
    "title": "Citations",
    "section": "Citations",
    "text": "Citations\n\n\n\nNote: these citations are for all possible programs that may be used by pathogensurveillance. The final report will only present citations of programs used in the current run.\n\n\nAndrews, Simon et al. 2010. “FastQC: A Quality Control Tool for High Throughput Sequence Data.” Cambridge, United Kingdom.\n\n\nBayliss, Sion C, Harry A Thorpe, Nicola M Coyle, Samuel K Sheppard, and Edward J Feil. 2019. “PIRATE: A Fast and Scalable Pangenomics Toolbox for Clustering Diverged Orthologues in Bacteria.” Gigascience 8 (10): giz119.\n\n\nBrown, C Titus, and Luiz Irber. 2016. “Sourmash: A Library for MinHash Sketching of DNA.” Journal of Open Source Software 1 (5): 27.\n\n\nBushnell, Brian. 2014. “BBMap: A Fast, Accurate, Splice-Aware Aligner.”\n\n\nChen, Shifu. 2023. “Ultrafast One-Pass FASTQ Data Preprocessing, Quality Control, and Deduplication Using Fastp.” Imeta 2 (2): e107.\n\n\nCrusoe, Michael R, Hussien F Alameldin, Sherine Awad, Elmar Boucher, Adam Caldwell, Reed Cartwright, Amanda Charbonneau, et al. 2015. “The Khmer Software Package: Enabling Efficient Nucleotide Sequence Analysis.” F1000Research 4.\n\n\nDanecek, Petr, Adam Auton, Goncalo Abecasis, Cornelis A Albers, Eric Banks, Mark A DePristo, Robert E Handsaker, et al. 2011. “The Variant Call Format and VCFtools.” Bioinformatics 27 (15): 2156–58.\n\n\nDanecek, Petr, James K Bonfield, Jennifer Liddle, John Marshall, Valeriu Ohan, Martin O Pollard, Andrew Whitwham, et al. 2021. “Twelve Years of SAMtools and BCFtools.” Gigascience 10 (2): giab008.\n\n\nDi Tommaso, Paolo, Maria Chatzou, Evan W Floden, Pablo Prieto Barja, Emilio Palumbo, and Cedric Notredame. 2017. “Nextflow Enables Reproducible Computational Workflows.” Nature Biotechnology 35 (4): 316–19.\n\n\nDistribution, Anaconda Software. 2016. “Computer Software.” Vers. 4: 2–2.\n\n\nDylus, David, Adrian Altenhoff, Sina Majidian, Fritz J Sedlazeck, and Christophe Dessimoz. 2024. “Inference of Phylogenetic Trees Directly from Raw Sequencing Reads Using Read2Tree.” Nature Biotechnology 42 (1): 139–47.\n\n\nEggertsson, Hannes P, Hakon Jonsson, Snaedis Kristmundsdottir, Eirikur Hjartarson, Birte Kehr, Gisli Masson, Florian Zink, et al. 2017. “Graphtyper Enables Population-Scale Genotyping Using Pangenome Graphs.” Nature Genetics 49 (11): 1654–60.\n\n\nEwels, Philip A, Alexander Peltzer, Sven Fillinger, Harshil Patel, Johannes Alneberg, Andreas Wilm, Maxime Ulysse Garcia, Paolo Di Tommaso, and Sven Nahnsen. 2020. “The Nf-Core Framework for Community-Curated Bioinformatics Pipelines.” Nature Biotechnology 38 (3): 276–78.\n\n\nEwels, Philip, Måns Magnusson, Sverker Lundin, and Max Käller. 2016. “MultiQC: Summarize Analysis Results for Multiple Tools and Samples in a Single Report.” Bioinformatics 32 (19): 3047–48.\n\n\nGarrison, Erik, Zev N Kronenberg, Eric T Dawson, Brent S Pedersen, and Pjotr Prins. 2022. “A Spectrum of Free Software Tools for Processing the VCF Variant Call Format: Vcflib, Bio-Vcf, Cyvcf2, Hts-Nim and Slivar.” PLoS Computational Biology 18 (5): e1009123.\n\n\nGrüning, Björn, Ryan Dale, Andreas Sjödin, Brad A Chapman, Jillian Rowe, Christopher H Tomkins-Tinch, Renan Valieris, Johannes Köster, and Bioconda Team. 2018. “Bioconda: Sustainable and Comprehensive Software Distribution for the Life Sciences.” Nature Methods 15 (7): 475–76.\n\n\nKamvar, Zhian N, Javier F Tabima, and Niklaus J Grünwald. 2014. “Poppr: An r Package for Genetic Analysis of Populations with Clonal, Partially Clonal, and/or Sexual Reproduction.” PeerJ 2: e281.\n\n\nKatoh, Kazutaka, Kazuharu Misawa, Kei-ichi Kuma, and Takashi Miyata. 2002. “MAFFT: A Novel Method for Rapid Multiple Sequence Alignment Based on Fast Fourier Transform.” Nucleic Acids Research 30 (14): 3059–66.\n\n\nKolmogorov, Mikhail, Jeffrey Yuan, Yu Lin, and Pavel A Pevzner. 2019. “Assembly of Long, Error-Prone Reads Using Repeat Graphs.” Nature Biotechnology 37 (5): 540–46.\n\n\nKurtzer, Gregory M, Vanessa Sochat, and Michael W Bauer. 2017. “Singularity: Scientific Containers for Mobility of Compute.” PloS One 12 (5): e0177459.\n\n\nLi, Heng. 2011. “Tabix: Fast Retrieval of Sequence Features from Generic TAB-Delimited Files.” Bioinformatics 27 (5): 718–19.\n\n\nLi, Heng, and Richard Durbin. 2009. “Fast and Accurate Short Read Alignment with Burrows–Wheeler Transform.” Bioinformatics 25 (14): 1754–60.\n\n\nManni, Mosè, Matthew R Berkeley, Mathieu Seppey, Felipe A Simão, and Evgeny M Zdobnov. 2021. “BUSCO Update: Novel and Streamlined Workflows Along with Broader and Deeper Phylogenetic Coverage for Scoring of Eukaryotic, Prokaryotic, and Viral Genomes.” Molecular Biology and Evolution 38 (10): 4647–54.\n\n\nMikheenko, Alla, Andrey Prjibelski, Vladislav Saveliev, Dmitry Antipov, and Alexey Gurevich. 2018. “Versatile Genome Assembly Evaluation with QUAST-LG.” Bioinformatics 34 (13): i142–50.\n\n\nNguyen, Lam-Tung, Heiko A Schmidt, Arndt Von Haeseler, and Bui Quang Minh. 2015. “IQ-TREE: A Fast and Effective Stochastic Algorithm for Estimating Maximum-Likelihood Phylogenies.” Molecular Biology and Evolution 32 (1): 268–74.\n\n\n“Picard Toolkit.” 2019. Broad Institute, GitHub Repository. https://broadinstitute.github.io/picard/; Broad Institute.\n\n\nPrjibelski, Andrey, Dmitry Antipov, Dmitry Meleshko, Alla Lapidus, and Anton Korobeynikov. 2020. “Using SPAdes de Novo Assembler.” Current Protocols in Bioinformatics 70 (1): e102.\n\n\nQin, Qi-Long, Bin-Bin Xie, Xi-Ying Zhang, Xiu-Lan Chen, Bai-Cheng Zhou, Jizhong Zhou, Aharon Oren, and Yu-Zhong Zhang. 2014. “A Proposed Genus Boundary for the Prokaryotes Based on Genomic Insights.” Journal of Bacteriology 196 (12): 2210–15.\n\n\nR Core Team. 2021. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/.\n\n\nSayers, Eric W, Evan E Bolton, J Rodney Brister, Kathi Canese, Jessica Chan, Donald C Comeau, Ryan Connor, et al. 2022. “Database Resources of the National Center for Biotechnology Information.” Nucleic Acids Research 50 (D1): D20.\n\n\nSchwengers, Oliver, Lukas Jelonek, Marius Alfred Dieckmann, Sebastian Beyvers, Jochen Blom, and Alexander Goesmann. 2021. “Bakta: Rapid and Standardized Annotation of Bacterial Genomes via Alignment-Free Sequence Identification.” Microbial Genomics 7 (11): 000685.\n\n\nShen, Wei, Shuai Le, Yan Li, and Fuquan Hu. 2016. “SeqKit: A Cross-Platform and Ultrafast Toolkit for FASTA/q File Manipulation.” PloS One 11 (10): e0163962.\n\n\nVan der Auwera, Geraldine A, and Brian D O’Connor. 2020. Genomics in the Cloud: Using Docker, GATK, and WDL in Terra. O’Reilly Media.\n\n\nVeiga Leprevost, Felipe da, Björn A Grüning, Saulo Alves Aflitos, Hannes L Röst, Julian Uszkoreit, Harald Barsnes, Marc Vaudel, et al. 2017. “BioContainers: An Open-Source and Community-Driven Framework for Software Standardization.” Bioinformatics 33 (16): 2580–82.",
    "crumbs": [
      "Citations"
    ]
  },
  {
    "objectID": "faq.html",
    "href": "faq.html",
    "title": "faq",
    "section": "",
    "text": "How long does the pathogensurveillance take to run?\nHow many samples can be run at once?\nWhat are the minimum computational resources necessary to run pathogensurveillance?\nHow much sequencing coverage is needed?\nCan pathogensurveillance be run on macOS?\nHow are reference genomes selected?\nThis process works remarkably well for most use cases. However, there are some biological reasons why selecting a reference genome becomes a more challenging problem (with or without pathogensurveilance). First, if you are working with a truly unique organism, there may be no nearby reference. Second, closely related bacteria can still vary considerably their accessory genomes. This process will prioritze matches between core genes above other genomic content, like extra-chromosomal plasmids or other rapidly evolving/repetitive regions. If these regions are of diagnostic interest for your system, you may get better results if you are able to specify a known reference before running the pipeline."
  },
  {
    "objectID": "examplereports.html",
    "href": "examplereports.html",
    "title": "Example Reports",
    "section": "",
    "text": "example 1 report\n\nIruegas-Bocardo, Fernanda, et al. “Whole genome sequencing-based tracing of a 2022 introduction and outbreak of Xanthomonas hortorum pv. pelargonii.” Phytopathology® 113.6 (2023): 975-984.",
    "crumbs": [
      "Example Reports"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "tutorial.html#snp-trees",
    "href": "tutorial.html#snp-trees",
    "title": "Tutorial",
    "section": "\nSNP trees\n",
    "text": "SNP trees\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbout this plot\n\n\n\n\n\n\n\n\nThis is a representation of a Single Nucleotide Polymorphism (SNP) tree, depicting the genetic relationships among samples in comparison to a reference assembly.\n\n\nThe tree is less robust than a core gene phylogeny and cannot offer insights on evolutionary relationships among strains, but it does offer one way to visualize the genetic diversity among samples, with genetically similar strains clustering together.\n\n\nQuestion-does it make sense to be showing the reference within the tree?",
    "crumbs": [
      "Tutorial"
    ]
  },
  {
    "objectID": "tutorial.html#minimum-spanning-network",
    "href": "tutorial.html#minimum-spanning-network",
    "title": "Tutorial",
    "section": "\nMinimum spanning network\n",
    "text": "Minimum spanning network\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbout this plot\n\n\n\n\n\n\n\n\nThis figure depicts a minimium spanning network (MSN). The nodes represent unique multiocus genotypes, and the size of nodes is proportional to the # number of samples that share the same genotype.\n\n\nThe edges represent the SNP differences between two given genotypes, and the darker the color of the edges, the fewer SNP differences between the two.\n\n\nNote: within these MSNs, edge lengths are not proportional to SNP differences.",
    "crumbs": [
      "Tutorial"
    ]
  },
  {
    "objectID": "index.html#background---why-use-pathogensurveilance",
    "href": "index.html#background---why-use-pathogensurveilance",
    "title": "",
    "section": "Background - why use pathogensurveilance?",
    "text": "Background - why use pathogensurveilance?\nTL;DR:\nunknown FASTQ -&gt; sample ID + phylogeny + publication-quality figures\nMost existing genomic tools are designed to be used with a reference genome. Unfortunately, this is a luxury in the pathogen diagnostic world, where researchers often are faced with unknown samples. This creates a seemingly impossible problem: how can you draw a point of comparison without any starting point?\nPathogensurveilance addresses this by picking a good reference genome for you. In most cases, this will be the best reference. It is therefore a great option for identification of an unknown sample, or when you would like some empirical data suggesting which references are available in nearby species.\nPathogensurveilance uses several strategies to address the emerging complexity of working with sequences that could anything from plants to bacteria to fungus. First, pathogensurveilance uses reasonable baseline parameters that work very well with most species. There are some processes where a one-size-fits-all strategy isn’t feasible. In such cases, Pathogensurveilance will change the analysis workflow automatically (e.g. assembling Prokaryotic vs Eukaryotic core genes). These analysis branchpoints are facilitated by the Nextflow framework, and require no additional inputs from the user.\nWhile pathogensurveilance may be a useful tool for researchers of all levels, it was designed with clinicians in mind who may have limited bioinformatics training. Pathogensurveilance is very simple to run. At a minimum, all that needs to be supplied is a .CSV file with a single column specifying the path to your sample’s sequencing reads. For more experienced users, there are opportunities to customize the parameters of the pipeline. In particular, the final report is designed for configuration through by nature of Quarto and the psminer plugin system.\nPathogensurveilance is particularly good for:\n\nunknown sample ID\nexploratory population analysis using minimal input parameters\ninexperienced bioinformatics users\nrepeated analysis where you would like to compare a few new samples to a past run.\n\nPathogensurveilance is not designed for:\n\nviral sequence\nnon gDNA sequences (RNA-seq, RAD-seq, ChIP-seq, etc.)\nExperienced researchers who want to use a highly customizable pipeline"
  },
  {
    "objectID": "index.html#background",
    "href": "index.html#background",
    "title": "",
    "section": "Background - why use PathogenSurveillance?",
    "text": "Background - why use PathogenSurveillance?\nTL;DR: unknown gDNA FASTQ -&gt; sample ID + phylogeny + publication-quality figures\nMost genomic tools are designed to be used with a reference genome. Yet this is at odds with the work of pathogen diagnosticians, who often deal with unknown samples. Finding the right reference manually may be cumbersome and require a suprising amount of technical skill.\nPathogenSurveillance picks a good reference genome for you. It does this through the program sourmash. In simple terms, this takes a sample’s DNA “fingerprint” and finds the closest match in a “DNA fingerprint library” spanning the tree of life. In more technical terms, the pipeline generates k-mer sketches from your reads assembled into genomes, then uses the identified reference to do a boilerplate, but robust phylogenetic analysis of your submitted samples.\nIn our experience, the pipeline usually chooses the best possible reference genome. At a minimum it will choose a reference that is good enough to build an informative phylogeny and allow you to see the contextual placement your samples.\nPathogensurveillance is designed to use as many types of genomic DNA input as possible. It works for common shortread and longread sequencing technologies and for both prokaryotes and eukaryotes. There is a good deal of emergent complexity required to work with such a broad sample range, but Pathogensurveillance handles this automatically.\n\n\n\n\n\n\nTip\n\n\n\nIgnore the name - Pathogensurveillance works great for non pathogens too.\n\n\nWhile PathogenSurveillance may be a useful tool for researchers of all levels, it was designed with those who may have limited bioinformatics training in mind. PathogenSurveillance is very simple to run. At a minimum, all that needs to be supplied is a .CSV file with a single column specifying the path to your sample’s sequencing reads. Other information is optional, but if provided will used to customize the output report or conditionally use particular reference genomes.\nPathogensurveillance is particularly good for:\n\nunknown sample identification\nexploratory population analysis using minimal input parameters\ninexperienced bioinformatics users\nefficient parallelization of tasks\nrepeated analysis (given caching) where you would like to add new samples to a past run\n\nPathogensurveillance is not designed for:\n\nviral sequence\nnon gDNA datasets (DNA assembly fasta files, RNA-seq, RAD-seq, ChIP-seq, etc.)\nmixed/impure samples (this may change in future versions)\nHighly specialized population genetic analysis, or researchers who would like to extensively test parameters at each stage\n\n\n\n\n\n\n\nNote\n\n\n\nPathogensuveillance is built with Nextflow, which is a scientific workflow management system. Typically, Nextflow pipelines manage their many software dependencies through containers. It be complicated to get the recommended container systems (Singularity/Apptainer or Docker) working on MacOS or Windows, but running the pipeline in Linux machines or HPC clusters is typically straightforward.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "examplereports.html#xanthomonas",
    "href": "examplereports.html#xanthomonas",
    "title": "example reports",
    "section": "",
    "text": "Example 1\nData from Iruegas-Bocardo et al 2023:\n\nWhole Genome Sequencing-Based Tracing of a 2022 Introduction and Outbreak of Xanthomonas hortorum pv. pelargonii doi: 10.1094/PHYTO-09-22-0321-R."
  },
  {
    "objectID": "examplereports.html#mycobacterium",
    "href": "examplereports.html#mycobacterium",
    "title": "example reports",
    "section": "mycobacterium",
    "text": "mycobacterium\nExample 2\nData from Bryant et al. 2016:\n\nEmergence and spread of a human-transmissible multidrug-resistant nontuberculous mycobacterium doi: DOI: 10.1126/science.aaf8156."
  },
  {
    "objectID": "examplereports.html#example-1---xanthomonas",
    "href": "examplereports.html#example-1---xanthomonas",
    "title": "Example Reports",
    "section": "",
    "text": "example 1 report\n\nIruegas-Bocardo, Fernanda, et al. “Whole genome sequencing-based tracing of a 2022 introduction and outbreak of Xanthomonas hortorum pv. pelargonii.” Phytopathology® 113.6 (2023): 975-984.",
    "crumbs": [
      "Example Reports"
    ]
  },
  {
    "objectID": "examplereports.html#example-2---mycobacterium",
    "href": "examplereports.html#example-2---mycobacterium",
    "title": "Example Reports",
    "section": "Example 2 - mycobacterium",
    "text": "Example 2 - mycobacterium\nexample 2 report\n\nBryant, Josephine M., et al. “Population-level genomics identifies the emergence and global spread of a human transmissible multidrug-resistant nontuberculous mycobacterium.” Science (New York, NY) 354.6313 (2016): 751.",
    "crumbs": [
      "Example Reports"
    ]
  },
  {
    "objectID": "documentation.html#input-format",
    "href": "documentation.html#input-format",
    "title": "Documentation",
    "section": "Input format",
    "text": "Input format\n\nPrimary CSV file\nThe primary input to the pipeline is a CSV (comma comma-separated value). Columns can be in any order and unneeded columns can be left out or left blank. Only a single column containing paths to raw sequence data or SRA (Sequence Read Archive) accessions is required and each sample can have values in different columns. Any columns not recognized by pathogensurveillance will be ignored, allowing users to adapt existing sample metadata table by adding new columns. Below is a description of each column used by pathogensurveillance:\n\nsample_id: The unique identifier for each sample. This will be used in file names to distinguish samples in the output. Each sample ID must correspond to a single source of sequence data (e.g. the path and ncbi_accession columns), although the same sequence data can be used by different IDs. Any values supplied that correspond to different sources of sequence data or contain characters that cannot appear in file names (/:*?“&lt;&gt;| .) will be modified automatically. If not supplied, it will be inferred from the path, ncbi_accession, or name columns.\nname: A human-readable label for the sample that is used in plots and tables. If not supplied, it will be inferred from sample_id.\npath: Path to input sequence data, typically gzipped FASTQ files. When paired end sequencing is used, this is used for the forward read’s data and path_2 is used for the reverse reads. This can be a local file path or a URL to an online location. The sequence_type column must have a value.\npath_2: Path to the FASTQ files for the reverse read when paired-end sequencing is used. This can be a local file path or a URL to an online location. The sequence_type column must have a value.\nncbi_accession: An SRA accession ID for reads to be downloaded and used as samples. Values in the sequence_type column will be looked up if not supplied.\nncbi_query: A valid NCBI search query to search the SRA for reads to download and use as samples. This will result in an unknown number of samples being analyzed. The total number downloaded is limited by the ncbi_query_max column. Values in the sample_id, name, and description columns will be append to that supplied by the user. Values in the sequence_type column will be looked up and does not need to be supplied by the user.\nncbi_query_max: The maximum number or percentage of samples downloaded for the corresponding query in the ncbi_query column. Adding a % to the end of a number indicates a percentage of the total number of results instead of a count. A random of subset of results will be downloaded if ncbi_query_max is less than “100%” or the total number of results.\nsequence_type: The type of sequencing used to produce reads for the reads_1 and reads_2 columns. Valid values include anything containing the words “illumina”, “nanopore”, or “pacbio”. Will be looked up automatically for ncbi_accession and ncbi_query inputs but must be supplied by the user for path inputs.\nreport_group_ids: How to group samples into reports. For every unique value in this column a report will be generated. Samples can be assigned to multiple reports by separating group IDs by “;”. For example all;subset will put the sample in both all and subset report groups. Samples will be added to a default group if this is not supplied.\ncolor_by: The names of other columns that contain values used to color samples in plots and figures in the report. Multiple column names can be separated by “;”. Specified columns can contain either categorical factors or specific colors, specified as a hex code. By default, samples will be one color and references another.\nploidy: The ploidy of the sample. Should be a number. Defaults to “1”.\nenabled: Either “TRUE” or “FALSE”, indicating whether the sample should be included in the analysis or not. Defaults to “TRUE”.\nref_group_ids: One or more reference group IDs separated by “;”. These are used to supply specific references to specific samples. These IDs correspond to IDs listed in the ref_group_ids or ref_id columns of the reference metadata CSV.\n\n\n\nSpecifying custom references\nAdditionally, users can supply a reference metadata CSV that can be used to assign custom references to particular samples. This is an optional step References are assigned to samples if they share a reference group ID in the ref_group_ids columns that can appear in both input CSVs. The reference metadata CSV can have the following columns:\n\nref_group_ids: One or more reference group IDs separated by “;”. These are used to group references and supply an ID that can be used in the ref_group_ids column of the sample metadata CSV to assign references to particular samples.\nref_id: The unique identifier for each user-defined reference genome. This will be used in file names to distinguish samples in the output. Each reference ID must correspond to a single source of reference data (The ref_path, ref_ncbi_accession, and ref_ncbi_query columns), although the same reference data can be used by multiple IDs. Any values that correspond to different sources of reference data or contain characters that cannot appear in file names (/:*?“&lt;&gt;| .) will be modified automatically. If not supplied, it will be inferred from the path, ref_name columns or supplied automatically when ref_ncbi_accession or ref_ncbi_query are used.\nref_name: A human-readable label for user-defined reference genomes that is used in plots and tables. If not supplied, it will be inferred from ref_id. It will be supplied automatically when the ref_ncbi_query column is used.\nref_description: A longer human-readable label for user-defined reference genomes that is used in plots and tables. If not supplied, it will be inferred from ref_name. It will be supplied automatically when the ref_ncbi_query column is used.\nref_path: Path to user-defined reference genomes for each sample. This can be a local file path or a URL to an online location.\nref_ncbi_accession: RefSeq accession ID for a user-defined reference genome. These will be automatically downloaded and used as input.\nref_ncbi_query: A valid NCBI search query to search the assembly database for genomes to download and use as references. This will result in an unknown number of references being downloaded. The total number downloaded is limited by the ref_ncbi_query_max column. Values in the ref_id, ref_name, and ref_description columns will be append to that supplied by the user.\nref_ncbi_query_max: The maximum number or percentage of references downloaded for the corresponding query in the ref_ncbi_query column. Adding a % to the end of a number indicates a percentage of the total number of results instead of a count. A random of subset of results will be downloaded if ncbi_query_max is less than “100%” or the total number of results.\nref_primary_usage: Controls how the reference is used in the analysis in cases where a single “best” reference is required, such as for variant calling. Can be one of “optional” (can be used if selected by the analysis), “required” (will always be used), “exclusive” (only those marked “exclusive” will be used), or “excluded” (will not be used).\nref_contextual_usage: Controls how the reference is used in the analysis in cases where multiple references are required to provide context for the samples, such as for phylogeny. Can be one of “optional” (can be used if selected by the analysis), “required” (will always be used), “exclusive” (only those marked “exclusive” will be used), or “excluded” (will not be used).\nref_color_by: The names of other columns that contain values used to color references in plots and figures in the report. Multiple column names can be separated by “;”. Specified columns can contain either categorical factors or specific colors, specified as a hex code. By default, samples will be one color and references another.\nref_enabled: Either “TRUE” or “FALSE”, indicating whether the reference should be included in the analysis or not. Defaults to “TRUE”.",
    "crumbs": [
      "Documentation"
    ]
  },
  {
    "objectID": "documentation.html#command-line-options",
    "href": "documentation.html#command-line-options",
    "title": "Documentation",
    "section": "",
    "text": "Required:\n\n--input: Path to comma-separated file containing information about the samples in the experiment.\n--output: The output directory where the results will be saved. You have to use absolute paths to storage on Cloud infrastructure.\n--bakta_db: The path to the Bakta database folder. This or --download_bakta_db must be included.\n--download_bakta_db: Download the database required for running Bakta. Note that this will download gigabytes of information, so if you plan on running the pipeline repeatedly it would be better to download the database manually and specify the path with --bakta_db.\n\nNextflow Options:\n\n-profile: Instructs the pipeline to use the named tool for software management. docker, singularity, podman, shifter, charliecloud and conda. For example, -profile test,docker\n-resume: Restarts an incomplete run by using cached intermediate files.\n\nOptional:\n\n--email: Set this parameter to your e-mail address to get a summary e-mail with details of the run sent to you when the workflow exits. If set in your user config file (`~/.nextflow/config`) then you don’t need to specify this on the command line for every run.\n--multiqc_title: MultiQC report title. Printed as page header, used for filename if not otherwise specified.\n\nPerformance Parameters:\n\n--max_cpus: Maximum number of CPUs that can be requested for any single job. Default: 16\n--max_memory: Maximum amount of memory that can be requested for any single job. Default: 128.GB\n--max_time: Maximum amount of time that can be requested for any single job. Default: 240.h\n\nAnalysis Parameters:\n\n--sketch_max_depth: Depth reads are subsampled to for the initial sketch-based identification. Default: 3\n--variant_max_depth: Depth reads are subsampled to for the variant-based parts of the analysis. Default: 15\n--assembly_max_depth: Depth reads are subsampled to for genome assembly. This will be multiplied by the predicted ploidy of each sample. Default: 30\n--refseq_download_num: The maximum number of RefSeq sequences to select and download for each sample at each taxonomic level (species, genus, and family). The total number will vary based on the diversity of samples. Default: 10\n--min_core_genes: The minimum number of genes needed to conduct a core gene phylogeny. Samples and references will be removed (as allowed by the min_core_samps and min_core_refs options) until this minimum is met. Default: 10\n--min_core_samps: The minimum proportion of samples needed to conduct a core gene phylogeny. Samples will be removed until the min_core_genes option is satisfied or this minimum is met. Default: 0.8\n--min_core_refs: The minimum proportion of references needed to conduct a core gene phylogeny. References will be removed until the min_core_genes option is satisfied or this minimum is met. Default: 0.5\n--max_core_genes: The maximum number of genes used to conduct a core gene phylogeny. Default: 100\n--min_ref_ani: The minimum ANI between a sample and potential reference for that reference to be used for variant calling with that sample. To force all the samples in a report group to use the same reference, set this value very low. Default: 0.9\n--copymode: Storage management setting to determine which files will be copied from the cache into the output directory.\n\nhigh - All files are copied into output directory.\nmedium - Reports are copied. Large sequencing files are not copied, but they are accessible through symlinks to their location in the cache (default).\nlow - No files are copied into output directory, but files are accessible through symlinks to their location in the cache.",
    "crumbs": [
      "Documentation"
    ]
  },
  {
    "objectID": "tutorial.html#example-1-standard-run",
    "href": "tutorial.html#example-1-standard-run",
    "title": "Tutorial",
    "section": "Example 1: Standard Run",
    "text": "Example 1: Standard Run\nThis example uses sequencing reads from an 2022 outbreak of the bacterial pathogen Xanthomonas hortorum found infecting geranium in several plant nurseries. Using whole-genome sequencing, researchers determined a shared genetic basis between strains at different locations. With this information, they traced the origin of the outbreak to a single supplier that sold infected cuttings. You can read more about the study here. \nWe’ll be treating the pathogen as an unknown and using the pathogensurveillance pipeline to determine what we know already (that these samples come from Xanthomonas hortorum). We’ll also see the high degree of shared DNA sequence between samples, which is seen from several plots that the pathogensurveillance pipeline generates automatically. \n\nSample input\nThe pipeline is designed to work with a wide variety of existing metadata sheets without extensive changes. Here’s a look at “xanthomonas.csv”, which serves as the only unique input file within the command to run the pipeline:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsample_id\npath_1\npath_2\nsequence_type\nreference\nreference_id\nreport_group\ncolor_by\ndate_isolated\ndate_received\nyear\nhost\ncv_key\nnursery\nX\nX.1\n\n\n\n\n22-299\ntest/data/reads/22-299_R1.fastq.gz\ntest/data/reads/22-299_R2.fastq.gz\nIllumina\n\n\nxan_test\nsubgroup\nyear\nnursery\n3/2/22\n3/29/22\n2022\nPelargonium x hortorum\nCV-1\nMD\n\n\n22-300\ntest/data/reads/22-300_R1.fastq.gz\ntest/data/reads/22-300_R2.fastq.gz\nIllumina\n\n\nxan_test\nsubgroup\nyear\nnursery\n3/2/22\n3/30/22\n2022\nPelargonium x hortorum\nCV-2\nMD\n\n\n22-301\ntest/data/reads/22-301_R1.fastq.gz\ntest/data/reads/22-301_R2.fastq.gz\nIllumina\n\n\nxan_test\nsubgroup\nyear\nnursery\n3/2/22\n3/31/22\n2022\nPelargonium x hortorum\nCV-3\nMD\n\n\n22-302\ntest/data/reads/22-302_R1.fastq.gz\ntest/data/reads/22-302_R2.fastq.gz\nIllumina\n\n\nxan_test\nsubgroup\nyear\nnursery\n3/2/22\n4/1/22\n2022\nPelargonium x hortorum\nCV-4\nMD\n\n\n22-303\ntest/data/reads/22-303_R1.fastq.gz\ntest/data/reads/22-303_R2.fastq.gz\nIllumina\n\n\nxan_test\nsubgroup\nyear\nnursery\n3/2/22\n4/2/22\n2022\nPelargonium x hortorum\nCV-5\nMD\n\n\n22-304\ntest/data/reads/22-304_R1.fastq.gz\ntest/data/reads/22-304_R2.fastq.gz\nIllumina\n\n\nxan_test\nsubgroup\nyear\nnursery\n3/7/22\n4/3/22\n2022\nPelargonium x hortorum\nCV-6\nMD\n\n\n\n\n\n\nThere is quite a bit of information in this file, but only a few columns are essential (and can be in any order). The input csv needs show the pipeline where to find the sequencing reads. These can either be present locally or they can be downloaded from the NCBI.\nSample ID: The “sample_id” column is used to name your samples. This information will be used in graphs, so it is recommended to keep names short but informative. If you do not include this column, sample IDs will be generated from the names of your fastq files.\nUsing local reads: Columns “path_1” and “path_2” specify the path to forward and reverse reads. Each row corresponds to one individual sample. Reads for this tutorial are hosted on the pathogensurveilance github repo. . If your reads are single-ended, “path_2” should be left blank.\nShortread/Longread sequences*: Information in the column “sequencing_type” tells the pipeline these are derived from illumina shortreads. Other options for this column are “nanopore” and “pacbio”.\nDownloading reads: Sequence files may instead be hosted on the NCBI. In that case, the “shortread_1/shortread_2” columns should be substituted with a single “SRA” column, and they will be downloaded right after the pipeline checks the sample sheet. These downloads will show up in the folder path_surveil_data/reads. See test/data/metadata/xanthomonas.csv for an example using this input format.\nSpecifying a reference genome (optional): The “reference_refseq” column may be useful when you are relatively confident as to the identity of your samples and would like to include one particular reference for comparison. See Example 2 for an explanation of how to designate mandatory and optional references.\nAssigning sample groups (optional): The optional column “color_by” is used for data visualization. It will assign one or more columns to serve as grouping factors for the output report. Here, samples will be grouped by the values of the “year” and “nursery” columns. Note that multiple factors need to be separated by semicolons within the color_by column. \n\n\nRunning the pipeline\nHere is the full command used execute this example, using a docker container:\nnextflow run nf-core/pathogensurveillance --inout https://raw.githubusercontent.com/grunwaldlab/pathogensurveillance/master/test/data/metadata/xanthomonas.csv --outdir xanthomonas --download_bakta_db true -profile docker -resume --max_cpus 8 --max_memory 30GB -resume\nWhen running your own analysis, you will need to provide your own path to the input CSV file.\nBy default, the pipeline will run on 128 GB of RAM and 16 threads. These are more resources than are strictly necessary and beyond the capacity of most desktop computers. We can scale this back a bit for this lightweight test run. This analysis will work with 8 CPUs and 30 GB of RAM (albeit more slowly), which is specified by the –max_cpus and –max_memory settings.\nThe setting -resume is only necessary when resuming a previous analysis. However, it doesn’t hurt to include it at the start. If the pipeline is interrupted, this setting allows progress to pick up where it left off – as long as the previous command is executed from the same working directory.\nIf the pipeline begins successfully, you should see a screen tracking your progress:\n[25/63dcee] process &gt; PATHOGENSURVEILLANCE:INPUT_CHECK:SAMPLESHEET_CHECK (xanthomonas.csv)[100%] 1 of 1\n[-        ] process &gt; PATHOGENSURVEILLANCE:SRATOOLS_FASTERQDUMP                              -\n[-        ] process &gt; PATHOGENSURVEILLANCE:DOWNLOAD_ASSEMBLIES                               -\n[-        ] process &gt; PATHOGENSURVEILLANCE:SEQKIT_SLIDING                                    -\n[-        ] process &gt; PATHOGENSURVEILLANCE:FASTQC                                            -\n[-        ] process &gt; PATHOGENSURVEILLANCE:COARSE_SAMPLE_TAXONOMY:BBMAP_SENDSKETCH           -\nThe input and output of each process can be accessed from the work/ directory. The subdirectory within work/ is designated by the string to left of each step. Note that this location will be different each time the pipeline is run, and only the first part of the name of the subdirectory is shown. For this run, we could navigate to work/25/63dcee(etc) to access the input csv that is used for the next step. \n\n\nReport\nYou should see a message similar to this if the pipeline finishes successfully:\n-[nf-core/plantpathsurveil] Pipeline completed successfully-\n\nTo clean the cache, enter the command: \nnextflow clean evil_boyd -f \n\nCompleted at: 20-May-2024 12:44:40\nDuration    : 3h 29m 2s\nCPU hours   : 15.2\nSucceeded   : 253\nThe final report can be viewed as either a .pdf or .html file. It can be accessed inside the reports folder of the output directory (here: xanthomonas/reports). This report shows several key pieces of information about your samples.\nA note on storage management - pathogensurveillance creates a large number of intermediate files. For most users we recommend clearing these files after each run. To do so, run the script shown after the completion message (nextflow clean  -f). You would not want to do this if: (1) You still need to use the caching system. For example, imagine you would like to compare a new sample to 10 samples from a previous run. In that case, some files could be reused to make the pipeline work more quickly. (2) You would like to use intermediate files for your own analysis. By default, these files are saved in the output directory as symlinks to their location in the work/ directory, so you would need to retrieve these before clearing the cache. You could use alternatively use the option –copymode high to save all intermediate files to the published directory, though in the short term this doubles the storage footprint of each run.\nThis particular report has been included as an example \n\nSummary:\n\nPipeline Status Report: error messages for samples or sample groups\nInput Data: Data read from the input .csv file\n\n\nIdentification:\n\nInitial identification: Coarse identification from the bbmap sendsketch step. The first tab shows best species ID for each sample. The second tab shows similarity metrics between sample sequences and other reference genomes: %ANI (average nucleotide identity), %WKID (weighted kmer identity), and %completeness.\n\nFor more information about each metric, click the About this table tab underneath.\n\n\n\n\nMost similar organisms: Shows relationships between samples and references using % ani and % pocp (percentage of conserved proteins). For better resolution, you can interactively zoom in/out of plots.\n\n\nCore gene phylogeny: A core gene phylogeny uses the sequences of all gene shared by all of the genomes included in the tree to infer evolutionary relationships. It is the most robust identification provided by this pipeline, but its precision is still limited by the availability of similar reference sequences. Methods to generate this tree differ between prokaryotes and eukaryotes. Our input to the pipeline was prokaryotic DNA sequences, and the method to build this tree is based upon many different core genes shared between samples and references (for eukaryotes, this is constrained to BUSCO genes). This tree is built with iqtree and based upon shared core genes analyzed using the program pirate.\n\n\n\nSNP trees: This tree is better suited for visualizing the genetic diversity among samples. However, the core gene phylogeny provides a much better source of information for evolutionary differences among samples and other known references.\n\n\nMinimum spanning network\n\nMinimum spanning network: The nodes represent unique multilocus genotypes, and the size of nodes is proportional to the # number of samples that share the same genotype. The edges represent the SNP differences between two given genotypes, and the darker the color of the edges, the fewer SNP differences between the two.",
    "crumbs": [
      "Tutorial"
    ]
  },
  {
    "objectID": "tutorial.html#example-2-defining-references",
    "href": "tutorial.html#example-2-defining-references",
    "title": "Tutorial",
    "section": "Example 2: Defining References",
    "text": "Example 2: Defining References\nIf you know what your samples are already, you may want to tell the pipeline to use a “standard” reference genome instead of picking one that is more obscure – even if pathogensurveillance deems the alternative to be a better fit. Other users may have a few different organisms of interest that they want to use as a points of comparison. For example, maybe there is a particularly nasty strain of V. cholerae that you want to see in relation to your other samples. There are a few options to select (or not select) reference genomes for these cases.\nPathogensurveillance uses two categories of reference genomes. Primary references are used for alignment and will always be displayed in phylogenetic trees. In contrast, contextual references are selected before the primary reference is known and they may or may not be used later. Some contextual references are chosen because they are really close matches to your samples, and these may be selected to become primary references. However, pathogensurveillance will select a few distantly related contextual references too. Some of these are used to “fill out” the phylogeny, and you may want a higher or lower number of contextual references depending on how you want your phylogenetic trees to look.\n\nChosing primary references\nTake this sample list containing three Mycobacterium abscessus samples and three Mycobacterium leprae samples:\n\n\n\n\n\n\nsample_id\nncbi.accession\n\n\n\n\nmycobacterium_abscessus1\nERR7253671\n\n\nmycobacterium_abscessus2\nERR7253669\n\n\nmycobacterium_abscessus3\nERR7253671\n\n\nmycobacterium_leperae1\nSRR6241707\n\n\nmycobacterium_leperae2\nSRR6241708\n\n\nmycobacterium_leperae3\nSRR6241709\n\n\n\n\n\n\nTo force the pipeline to use the NCBI specified Mycobacterium abscessus reference genome for the three Mycobacterium abscessus samples, and likewise make the three Mycobacterium leprae samples use the NCBI specified Mycobacterium leprae genome, we need to tell pathogensurveillance both where to find these reference sequences and how to use them. We can either specify a local path to the reads, or this can instead be specified through the ref_ncbi_accession column. Here, how the references are used here is controlled by the ref_primary_usage column:\n\n\n\n\n\n\n\n\n\n\n\n\nsample_id\nncbi.accession\nref_ncbi_accession\nref_primary_usage\n\n\n\n\nmycobacterium_abscessus1\nERR7253671\nGCF_001632805.1\nrequired\n\n\nmycobacterium_abscessus2\nERR7253669\nGCF_001632805.1\nrequired\n\n\nmycobacterium_abscessus3\nERR7253671\nGCF_001632805.1\nrequired\n\n\nmycobacterium_leprae1\nSRR6241707\nGCF_003253775.1\nrequired\n\n\nmycobacterium_leprae2\nSRR6241708\nGCF_003253775.1\nrequired\n\n\nmycobacterium_leprae3\nSRR6241709\nGCF_003253775.1\nrequired\n\n\n\n\n\n\n\n\n\nSpecifying contextual references\nTaking the previous Mycobacterium abscessus/leprae example, imagine we would like to see the comparison between Mycobacterium abscessus and Mycobacterium tuberculosis. We can do this by including Mycobacterium tuberculosis as a mandatory contextual reference:\n\n\n\n\n\n\n\n\n\n\n\n\nsample_id\nncbi.accession\nref_ncbi_accession\nref_contextual_usage\n\n\n\n\nmycobacterium_abscessus1\nERR7253671\nGCF_001632805.1\nrequired\n\n\nmycobacterium_abscessus2\nERR7253669\nGCF_001632805.1\nrequired\n\n\nmycobacterium_abscessus3\nERR7253671\nGCF_001632805.1\nrequired\n\n\nmycobacterium_leprae1\nSRR6241707\n\n\n\n\nmycobacterium_leprae2\nSRR6241708\n\n\n\n\nmycobacterium_leprae3\nSRR6241709\n\n\n\n\n\n\n\n\n\n\n\nSelecting references from an NCBI query\nIt is also possible to submit a valid NCBI query to the pipeline with reference genomes selected from query hits. For example, you could test how your Mycobacterium leprae samples compared to a bunch of different other Mycobacterium leprae genomes:\n\n\n\n\n\n\n\n\n\n\n\n\nsample_id\nncbi.accession\nref_ncbi_query\nref_ncbi_query_max\n\n\n\n\nmycobacterium_abscessus1\nERR7253671\n\nNA\n\n\nmycobacterium_abscessus2\nERR7253669\n\nNA\n\n\nmycobacterium_abscessus3\nERR7253671\n\nNA\n\n\nmycobacterium_leprae1\nSRR6241707\nmycobacterium leprae\n100\n\n\nmycobacterium_leprae2\nSRR6241708\nmycobacterium leprae\n100\n\n\nmycobacterium_leprae3\nSRR6241709\nmycobacterium leprae\n100\n\n\n\n\n\n\nSome things to keep in mind:\n\nDepending on your organism, this may a massive amount of data. Make sure you have queried NCBI beforehand to get a good handle on how many references you are downloading.\nThe optional parameter ref_ncbi_query_max is a good way of limiting this number when you are sampling from a densely populated clade, such as Mycobacterium leprae. This parameter can either be a set number (like shown here) or a percentage.\nThe NCBI API will fail if there are too many requests. See ncbi support for more detail.\n\n\n\n\nMultiple references per sample\nIf we would like to add multiple references per sample, we can enter this information through a separate reference csv. In this example, we specify one primary reference each for Mycobacterium abscessus and Mycobacterium leprae, then three additional contextual references for Mycobacterium leprae:\n\n\n\n\n\n\n\n\n\n\n\n\nref_group_ids\nref_path\nRef.primary.usage\nRef.contextual.Usage\n\n\n\n\nabscessus\ntest/data/refs/mycobacterium_abscessus_reference1.fna\nrequired\n\n\n\nleprae\ntest/data/refs/mycobacterium_leprae_reference1.fna\nrequired\n\n\n\nleprae\ntest/data/refs/mycobacterium_leprae_reference2.fna\n\noptional\n\n\nleprae\ntest/data/refs/mycobacterium_leprae_reference3.fna\n\noptional\n\n\nleprae\ntest/data/refs/mycobacterium_leprae_reference4.fna\n\noptional\n\n\n\n\n\n\nNote that the “ref_group_ids” column in the sample input csv needs to match the sample csv:\n\n\n\n\n\n\nsample_id\nncbi.accession\nref_group_ids\n\n\n\n\nmycobacterium_abscessus1\nERR7253671\nabscessus\n\n\nmycobacterium_abscessus2\nERR7253669\nabscessus\n\n\nmycobacterium_abscessus3\nERR7253671\nabscessus\n\n\nmycobacterium_leprae1\nSRR6241707\nleprae\n\n\nmycobacterium_leprae2\nSRR6241708\nleprae\n\n\nmycobacterium_leprae3\nSRR6241709\nleprae\n\n\n\n\n\n\nThe path to this reference csv needs to be specified in the command to run the pipeline:\nnextflow run nf-core/pathogensurveillance --sample_data mycobacterium_samples.csv --reference_input mycobacterium_references.csv --out_dir mycobacterium_test --download_bakta_db true -profile docker",
    "crumbs": [
      "Tutorial"
    ]
  }
]